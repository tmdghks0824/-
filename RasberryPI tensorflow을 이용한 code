import cv2
import serial
import time
import numpy as np
from tflite_runtime.interpreter import Interpreter

# 아두이노 시리얼 포트 설정 (포트 번호는 환경에 맞게 변경해야 함)
arduino = serial.Serial('/dev/ttyUSB0', 9600)
time.sleep(2)  # 시리얼 통신 안정화

# TensorFlow Lite 모델 경로
MODEL_PATH = "ssd_mobilenet_v2.tflite"
LABELS_PATH = "labels.txt"

# TensorFlow Lite Interpreter 초기화
interpreter = Interpreter(model_path=MODEL_PATH)
interpreter.allocate_tensors()

# 입력 및 출력 텐서 정보 가져오기
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_shape = input_details[0]['shape']

# 클래스 레이블 로드
def load_labels(path):
    with open(path, "r") as f:
        return [line.strip() for line in f.readlines()]

labels = load_labels(LABELS_PATH)

# 카메라 열기
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)  # 해상도 낮추기
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)

if not cap.isOpened():
    print("\u274c Failed to open camera")
    exit()

# 명령 전송 함수
def send_command(command):
    arduino.write(command.encode())  # 아두이노로 명령 전송
    print(f"Sent command: {command}")

while True:
    ret, frame = cap.read()
    if not ret:
        print("\u274c Failed to grab frame")
        break

    # 이미지 전처리
    input_image = cv2.resize(frame, (input_shape[2], input_shape[1]))
    input_image = np.expand_dims(input_image, axis=0)
    input_image = np.array(input_image, dtype=np.uint8)

    # 모델 실행
    interpreter.set_tensor(input_details[0]['index'], input_image)
    interpreter.invoke()

    # 출력 텐서 가져오기
    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding boxes
    class_ids = interpreter.get_tensor(output_details[1]['index'])[0]  # Class IDs
    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence scores

    # 기본값 (정지)
    command = 'S'
    obstacle_detected = False  # 장애물 감지 여부

    for i, score in enumerate(scores):
        if score > 0.5:  # 신뢰도 임계값
            ymin, xmin, ymax, xmax = boxes[i]
            x1, y1, x2, y2 = int(xmin * frame.shape[1]), int(ymin * frame.shape[0]), int(xmax * frame.shape[1]), int(ymax * frame.shape[0])
            class_id = int(class_ids[i])
            label = labels[class_id]

            # 감지된 객체 표시
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"{label}: {score:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # 장애물 감지 시 정지 후 후진
            if label in ["person", "car", "truck", "stop sign"]:
                obstacle_detected = True
                command = 'S'

    # 장애물이 감지되면 일정 시간 후진
    if obstacle_detected:
        send_command('S')  # 먼저 정지
        time.sleep(1)  # 1초 정지
        send_command('B')  # 후진
        time.sleep(1)  # 1초 후진
        send_command('S')  # 다시 정지
    else:
        # 차선 감지 (좌측이면 좌회전, 우측이면 우회전)
        for i, score in enumerate(scores):
            if score > 0.5:
                class_id = int(class_ids[i])
                label = labels[class_id]

                if label == "lane_left":
                    command = 'L'
                elif label == "lane_right":
                    command = 'R'
                else:
                    command = 'F'  # 장애물이 없으면 전진

        send_command(command)  # 아두이노로 명령 전송

    # 결과 화면 출력
    cv2.imshow("TensorFlow Lite Object Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 종료 처리
cap.release()
cv2.destroyAllWindows()
arduino.close()
